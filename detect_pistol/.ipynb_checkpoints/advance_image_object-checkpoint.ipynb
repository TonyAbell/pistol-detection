{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES - Connected.\n",
      "Took 0.314861089020269 seconds to unpersist the graph\n",
      "Took 10.675077615014743 seconds to find people in image\n",
      "Took 0.36476834199856967 seconds to perform image recognition on people found\n",
      "Took 0.7326722650032025 seconds to perform image recognition on people found\n",
      "Took 1.0935931699932553 seconds to perform image recognition on people found\n",
      "Took 1.4552884729928337 seconds to perform image recognition on people found\n",
      "Took 1.8210942489968147 seconds to perform image recognition on people found\n",
      "Took 10.262778458010871 seconds to find people in image\n",
      "Took 0.3610168160230387 seconds to perform image recognition on people found\n",
      "Took 0.7274349090002943 seconds to perform image recognition on people found\n",
      "Took 1.094651548017282 seconds to perform image recognition on people found\n",
      "Took 1.4646568860043772 seconds to perform image recognition on people found\n",
      "Took 1.836669331009034 seconds to perform image recognition on people found\n",
      "Took 10.194365525007015 seconds to find people in image\n",
      "Took 0.3702716940024402 seconds to perform image recognition on people found\n",
      "Took 0.7350994239968713 seconds to perform image recognition on people found\n",
      "Took 1.1070100170036312 seconds to perform image recognition on people found\n",
      "Took 1.4731388119980693 seconds to perform image recognition on people found\n",
      "Took 1.842707228002837 seconds to perform image recognition on people found\n",
      "Took 10.219672786974115 seconds to find people in image\n",
      "Took 0.36807648598914966 seconds to perform image recognition on people found\n",
      "Took 0.7343044349981938 seconds to perform image recognition on people found\n",
      "Took 1.094027957005892 seconds to perform image recognition on people found\n",
      "Took 1.4637352440040559 seconds to perform image recognition on people found\n",
      "Took 1.8311912640056107 seconds to perform image recognition on people found\n",
      "Took 10.19937609898625 seconds to find people in image\n",
      "Took 0.3721810980059672 seconds to perform image recognition on people found\n",
      "Took 0.7428716200229246 seconds to perform image recognition on people found\n",
      "Took 1.1108040219987743 seconds to perform image recognition on people found\n",
      "Took 1.4730602390191052 seconds to perform image recognition on people found\n",
      "Took 1.8443658059986774 seconds to perform image recognition on people found\n",
      "Took 10.189422844006913 seconds to find people in image\n",
      "Took 0.3729125469981227 seconds to perform image recognition on people found\n",
      "Took 0.7394066549895797 seconds to perform image recognition on people found\n",
      "Took 1.1094368289923295 seconds to perform image recognition on people found\n",
      "Took 1.4828213969885837 seconds to perform image recognition on people found\n",
      "Took 1.8554026019992307 seconds to perform image recognition on people found\n",
      "Took 10.300869549013441 seconds to find people in image\n",
      "Took 0.38021085801301524 seconds to perform image recognition on people found\n",
      "Took 0.7548736380122136 seconds to perform image recognition on people found\n",
      "Took 1.1284288780007046 seconds to perform image recognition on people found\n",
      "Took 1.505808252026327 seconds to perform image recognition on people found\n",
      "Took 1.9308884560014121 seconds to perform image recognition on people found\n",
      "Took 10.260333104990423 seconds to find people in image\n",
      "Took 0.374455579003552 seconds to perform image recognition on people found\n",
      "Took 0.7468942790001165 seconds to perform image recognition on people found\n",
      "Took 1.1286802009854 seconds to perform image recognition on people found\n",
      "Took 1.5194634899962693 seconds to perform image recognition on people found\n",
      "Took 1.9021638910053298 seconds to perform image recognition on people found\n",
      "Took 10.278004809020786 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 50, 54, 184299), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2475, 'xmax': 2756, 'ymin': 1447, 'ymax': 1520}\n",
      "Horizontal Angle12.880923569202423\n",
      " Vertical Angle -13.101755142211916\n",
      " Head Vertical Angle -8.233888816833497\n",
      "Took 0.816383029014105 seconds to perform image recognition on people found\n",
      "Took 1.2085974460060243 seconds to perform image recognition on people found\n",
      "Took 1.5801308730151504 seconds to perform image recognition on people found\n",
      "Took 1.9649161859997548 seconds to perform image recognition on people found\n",
      "Took 2.333375435991911 seconds to perform image recognition on people found\n",
      "Took 10.313934821024304 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 51, 6, 912833), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2487, 'xmax': 2779, 'ymin': 1452, 'ymax': 1523}\n",
      "Horizontal Angle13.197213768959045\n",
      " Vertical Angle -13.06582808494568\n",
      " Head Vertical Angle -8.32474544843038\n",
      "Took 0.642962722980883 seconds to perform image recognition on people found\n",
      "Took 1.0421678769926075 seconds to perform image recognition on people found\n",
      "Took 1.4236408879805822 seconds to perform image recognition on people found\n",
      "Took 1.7974881239933893 seconds to perform image recognition on people found\n",
      "Took 2.1734604869852774 seconds to perform image recognition on people found\n",
      "Took 10.392827442003181 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 51, 19, 555221), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2488, 'xmax': 2782, 'ymin': 1451, 'ymax': 1522}\n",
      "Horizontal Angle13.235698938369751\n",
      " Vertical Angle -13.030395388603212\n",
      " Head Vertical Angle -8.299764792124432\n",
      "Took 0.5405161989910994 seconds to perform image recognition on people found\n",
      "Took 0.9348647409933619 seconds to perform image recognition on people found\n",
      "Took 1.310846742009744 seconds to perform image recognition on people found\n",
      "Took 1.6878830100176856 seconds to perform image recognition on people found\n",
      "Took 2.063310122000985 seconds to perform image recognition on people found\n",
      "Took 10.253762348002056 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 51, 31, 951720), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2490, 'xmax': 2779, 'ymin': 1458, 'ymax': 1529}\n",
      "Horizontal Angle13.214031457901001\n",
      " Vertical Angle -13.139920592308046\n",
      " Head Vertical Angle -8.43590366045634\n",
      "Took 0.5088754829776008 seconds to perform image recognition on people found\n",
      "Took 0.9108728709979914 seconds to perform image recognition on people found\n",
      "Took 1.295939236995764 seconds to perform image recognition on people found\n",
      "Took 1.7034852929937188 seconds to perform image recognition on people found\n",
      "Took 2.1237087579793297 seconds to perform image recognition on people found\n",
      "Took 10.621990280022146 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 51, 44, 794606), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2482, 'xmax': 2774, 'ymin': 1451, 'ymax': 1523}\n",
      "Horizontal Angle13.107281029224396\n",
      " Vertical Angle -13.083141207695009\n",
      " Head Vertical Angle -8.308584086100261\n",
      "Took 0.6108564340102021 seconds to perform image recognition on people found\n",
      "Took 1.0013203349953983 seconds to perform image recognition on people found\n",
      "Took 1.3823332239990123 seconds to perform image recognition on people found\n",
      "Took 1.7667381099890918 seconds to perform image recognition on people found\n",
      "Took 2.1549328539986163 seconds to perform image recognition on people found\n",
      "Took 11.14391680402332 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 51, 58, 185647), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2477, 'xmax': 2773, 'ymin': 1453, 'ymax': 1525}\n",
      "Horizontal Angle13.054885506629944\n",
      " Vertical Angle -13.14705801010132\n",
      " Head Vertical Angle -8.348018089930218\n",
      "Took 0.5330851369944867 seconds to perform image recognition on people found\n",
      "Took 0.9327101430098992 seconds to perform image recognition on people found\n",
      "Took 1.3268501989950892 seconds to perform image recognition on people found\n",
      "Took 1.7315328390104696 seconds to perform image recognition on people found\n",
      "Took 2.1357452369993553 seconds to perform image recognition on people found\n",
      "Took 10.653324290004093 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 52, 11, 19903), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2491, 'xmax': 2783, 'ymin': 1453, 'ymax': 1524}\n",
      "Horizontal Angle13.28163230419159\n",
      " Vertical Angle -13.04634737968445\n",
      " Head Vertical Angle -8.336115137736003\n",
      "Took 0.5561698899837211 seconds to perform image recognition on people found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.9529237280075904 seconds to perform image recognition on people found\n",
      "Took 1.3312978769827168 seconds to perform image recognition on people found\n",
      "Took 1.7036066410073545 seconds to perform image recognition on people found\n",
      "Took 2.0865980699891225 seconds to perform image recognition on people found\n",
      "Took 10.499769988993648 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 52, 23, 670673), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2492, 'xmax': 2777, 'ymin': 1449, 'ymax': 1521}\n",
      "Horizontal Angle13.2262744307518\n",
      " Vertical Angle -13.04188895225525\n",
      " Head Vertical Angle -8.259857320785523\n",
      "Took 0.7879582190071233 seconds to perform image recognition on people found\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 52, 24, 476687), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2492, 'xmax': 2777, 'ymin': 1449, 'ymax': 1521}\n",
      "Horizontal Angle13.2262744307518\n",
      " Vertical Angle -13.04188895225525\n",
      " Head Vertical Angle -8.259857320785523\n",
      "Took 1.342718877014704 seconds to perform image recognition on people found\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 52, 25, 57681), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2492, 'xmax': 2777, 'ymin': 1449, 'ymax': 1521}\n",
      "Horizontal Angle13.2262744307518\n",
      " Vertical Angle -13.04188895225525\n",
      " Head Vertical Angle -8.259857320785523\n",
      "Took 1.9179682080284692 seconds to perform image recognition on people found\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 52, 25, 627827), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2492, 'xmax': 2777, 'ymin': 1449, 'ymax': 1521}\n",
      "Horizontal Angle13.2262744307518\n",
      " Vertical Angle -13.04188895225525\n",
      " Head Vertical Angle -8.259857320785523\n",
      "Took 2.507673590007471 seconds to perform image recognition on people found\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 52, 26, 208107), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2492, 'xmax': 2777, 'ymin': 1449, 'ymax': 1521}\n",
      "Horizontal Angle13.2262744307518\n",
      " Vertical Angle -13.04188895225525\n",
      " Head Vertical Angle -8.259857320785523\n",
      "Took 3.070154592016479 seconds to perform image recognition on people found\n",
      "Took 10.256524071999593 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 52, 37, 127862), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2493, 'xmax': 2777, 'ymin': 1453, 'ymax': 1525}\n",
      "Horizontal Angle13.234712898731232\n",
      " Vertical Angle -13.141196489334108\n",
      " Head Vertical Angle -8.350495926539104\n",
      "Took 0.664968996978132 seconds to perform image recognition on people found\n",
      "Took 1.0598554659809452 seconds to perform image recognition on people found\n",
      "Took 1.4307490279898047 seconds to perform image recognition on people found\n",
      "Took 1.8169874390005134 seconds to perform image recognition on people found\n",
      "Took 2.1968070289876778 seconds to perform image recognition on people found\n",
      "Took 10.271804475982208 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 52, 49, 659712), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2480, 'xmax': 2776, 'ymin': 1452, 'ymax': 1525}\n",
      "Horizontal Angle13.11409866809845\n",
      " Vertical Angle -13.209554672241213\n",
      " Head Vertical Angle -8.333328533172608\n",
      "Took 0.48822471499443054 seconds to perform image recognition on people found\n",
      "Took 0.8873037509911228 seconds to perform image recognition on people found\n",
      "Took 1.2568672049965244 seconds to perform image recognition on people found\n",
      "Took 1.6352423279895447 seconds to perform image recognition on people found\n",
      "Took 2.0100692239939235 seconds to perform image recognition on people found\n",
      "Took 10.399766615999397 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 53, 2, 151011), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2479, 'xmax': 2775, 'ymin': 1450, 'ymax': 1523}\n",
      "Horizontal Angle13.076540291309357\n",
      " Vertical Angle -13.195754528045656\n",
      " Head Vertical Angle -8.30712504386902\n",
      "Took 0.5715548369917087 seconds to perform image recognition on people found\n",
      "Took 0.9743537300091702 seconds to perform image recognition on people found\n",
      "Took 1.3592157420061994 seconds to perform image recognition on people found\n",
      "Took 1.7352852720068768 seconds to perform image recognition on people found\n",
      "Took 2.115597361989785 seconds to perform image recognition on people found\n",
      "Took 10.292092201998457 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 53, 14, 645171), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2487, 'xmax': 2774, 'ymin': 1453, 'ymax': 1524}\n",
      "Horizontal Angle13.162101447582245\n",
      " Vertical Angle -13.099574446678163\n",
      " Head Vertical Angle -8.34088233311971\n",
      "Took 0.5524835200048983 seconds to perform image recognition on people found\n",
      "Took 0.9419899109925609 seconds to perform image recognition on people found\n",
      "Took 1.3174069139931817 seconds to perform image recognition on people found\n",
      "Took 1.6940014690044336 seconds to perform image recognition on people found\n",
      "Took 2.0661208890087437 seconds to perform image recognition on people found\n",
      "Took 10.32177642500028 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 53, 27, 129234), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2485, 'xmax': 2775, 'ymin': 1456, 'ymax': 1527}\n",
      "Horizontal Angle13.133616328239441\n",
      " Vertical Angle -13.1514128446579\n",
      " Head Vertical Angle -8.393045759201051\n",
      "Took 0.636536009988049 seconds to perform image recognition on people found\n",
      "Took 1.0321523969760165 seconds to perform image recognition on people found\n",
      "Took 1.4137000949995127 seconds to perform image recognition on people found\n",
      "Took 1.7955900529923383 seconds to perform image recognition on people found\n",
      "Took 2.177176614990458 seconds to perform image recognition on people found\n",
      "Took 10.285083914001007 seconds to find people in image\n",
      "ES document sent.\n",
      "{'timestamp': datetime.datetime(2018, 7, 25, 12, 53, 39, 674905), 'content': 'Video information', 'text': 'Object detected.', 'xmin': 2484, 'xmax': 2773, 'ymin': 1453, 'ymax': 1525}\n",
      "Horizontal Angle13.103531539440155\n",
      " Vertical Angle -13.160748004913332\n",
      " Head Vertical Angle -8.35297096570333\n",
      "Took 0.5955182859906927 seconds to perform image recognition on people found\n",
      "Took 0.9906538939976599 seconds to perform image recognition on people found\n",
      "Took 1.3652341499982867 seconds to perform image recognition on people found\n",
      "Took 1.7464401419856586 seconds to perform image recognition on people found\n",
      "Took 2.1256662249797955 seconds to perform image recognition on people found\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "############################## Packages ###############################\n",
    "#######################################################################\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import timeit\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as img\n",
    "from IPython.display import Image, display, clear_output\n",
    "from elasticsearch import Elasticsearch \n",
    "from datetime import datetime \n",
    "\n",
    "# Setup ES \n",
    "try:\n",
    "    es = Elasticsearch(\n",
    "        [\n",
    "            'https://elastic:diatonouscoggedkittlepins@elasticsearch.orange.opswerx.org:443'\n",
    "        ],\n",
    "        verify_certs=True\n",
    "    )\n",
    "    print(\"ES - Connected.\")\n",
    "except Exception as ex:\n",
    "    print(\"Error: \", ex)\n",
    "\n",
    "#######################################################################\n",
    "################ Initialize Functions/Variables #######################\n",
    "#######################################################################\n",
    "\n",
    "# Science Thresholds\n",
    "\n",
    "person_threshold = 0.50\n",
    "person_gun_threshold = 0.80\n",
    "\n",
    "\n",
    "# Intialize Tensorflow session and gpu memory management\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "\n",
    "\n",
    "# Get Video and dimensions\n",
    "#cap = cv2.VideoCapture('overhead_east1.mp4') #original line\n",
    "cap = cv2.VideoCapture('/home/physblue/Videos/pic.jpg') #edited line\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "os.chdir(\"/home/physblue/models/research/object_detection/\") #original line\n",
    "#os.chdir(\"/models-master/research/object_detection/\") #edited line\n",
    "\n",
    "# ## Object detection imports\n",
    "# Here are the imports from the object detection module.\n",
    "\n",
    "\n",
    "# Needed if you want to make bounded boxes around person for object detection\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "##################### Model Preparation ###############################\n",
    "\n",
    "# ## Variables\n",
    "#\n",
    "# Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_CKPT` to point to a new .pb file.\n",
    "# By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies.\n",
    "\n",
    "\n",
    "# What model to download.\n",
    "MODEL_NAME = 'faster_rcnn_resnet101_coco_2017_11_08' #original line\n",
    "\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box and select person class\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "#Load a Object Detection Model(frozen) Tensorflow model into memory.\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "# Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,\n",
    "                                                            use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# Object Recognition model\n",
    "#label_lines = [line.rstrip() for line in tf.gfile.GFile(\"/tf_files/retrained_labels.txt\")] #original line\n",
    "label_lines = [line.rstrip() for line in tf.gfile.GFile(\"/home/physblue/pistol-detection/tf_files/retrained_labels.txt\")] #edited line\n",
    "\n",
    "\n",
    "def initialSetup():\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    # This takes 2-5 seconds to run\n",
    "    # Unpersists graph from file\n",
    "    #with tf.gfile.FastGFile('/tf_files/retrained_graph.pb', 'rb') as h: #original line\n",
    "    with tf.gfile.FastGFile('/home/physblue/pistol-detection/tf_files/retrained_graph.pb', 'rb') as h: #edited line\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(h.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    print('Took {} seconds to unpersist the graph'.format(timeit.default_timer() - start_time))\n",
    "\n",
    "\n",
    "initialSetup()\n",
    "\n",
    "\n",
    "# ## Helper code for frame processing\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "############# Perform object Detection and Recognition ################\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "\n",
    "################# Person Object Detection #############################\n",
    "\n",
    "count = 1\n",
    "person_count = 1\n",
    "\n",
    "\n",
    "# Loop Frame by Frame\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    count += 1\n",
    "    ret, image_np = cap.read()\n",
    "    if count%5 == 0:\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        # Loop Variables\n",
    "        wid = []\n",
    "        hei = []\n",
    "        head_hei = []\n",
    "        px  = []\n",
    "        py =  []\n",
    "        pxa = []\n",
    "        pya = []\n",
    "        pyha = []\n",
    "\n",
    "        # with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "            # while True:\n",
    "            # count += 1\n",
    "            # ret, image_np = cap.read()\n",
    "            # for image_path in TEST_IMAGE_PATHS:\n",
    "            count += 1\n",
    "            # image = img.open(image_path)\n",
    "            # image_np = load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "#             vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#               image_np,\n",
    "#               np.squeeze(boxes),\n",
    "#               np.squeeze(classes).astype(np.int32),\n",
    "#               np.squeeze(scores),\n",
    "#               category_index,\n",
    "#               use_normalized_coordinates=True,\n",
    "#               line_thickness=8)\n",
    "\n",
    "\n",
    "            xfov = 71\n",
    "            yfov = 44  \n",
    "            ch = 180\n",
    "            imageHeight = int(height)\n",
    "            imageWidth = int(width)\n",
    "            imageHeightCenter = imageHeight / 2\n",
    "            imageWidthCenter = imageWidth / 2\n",
    "            pixelDegreeHorizontal = float(xfov) / imageWidth\n",
    "            pixelDegreeVertical = float(yfov) / imageHeight\n",
    "\n",
    "            # Convert tensorflow data to pandas data frames\n",
    "            # print boxes\n",
    "            df = pd.DataFrame(boxes.reshape(300, 4), columns=['y_min', 'x_min', 'y_max', 'x_max'])\n",
    "            df1 = pd.DataFrame(classes.reshape(300, 1), columns=['classes'])\n",
    "            df2 = pd.DataFrame(scores.reshape(300, 1), columns=['scores'])\n",
    "            df5 = pd.concat([df, df1, df2], axis=1)\n",
    "\n",
    "            # Transform box bound coordinates to pixel coordintate\n",
    "\n",
    "            df5['y_min_t'] = df5['y_min'].apply(lambda x: x * imageHeight)\n",
    "            df5['x_min_t'] = df5['x_min'].apply(lambda x: x * imageWidth)\n",
    "            df5['y_max_t'] = df5['y_max'].apply(lambda x: x * imageHeight)\n",
    "            df5['x_max_t'] = df5['x_max'].apply(lambda x: x * imageWidth)\n",
    "\n",
    "            # Create objects pixel location x and y\n",
    "            # X\n",
    "            df5['ob_wid_x'] = df5['x_max_t'] - df5[\"x_min_t\"]\n",
    "            df5['ob_mid_x'] = df5['ob_wid_x'] / 2\n",
    "            df5['x_loc'] = df5[\"x_min_t\"] + df5['ob_mid_x']\n",
    "            # Y\n",
    "            df5['ob_hgt_y'] = df5['y_max_t'] - df5[\"y_min_t\"]\n",
    "            df5['ob_mid_y'] = df5['ob_hgt_y'] / 2\n",
    "            df5['y_loc'] = df5[\"y_min_t\"] + df5['ob_mid_y']\n",
    "            # Head\n",
    "            df5['ob_head_y'] = df5['ob_hgt_y'] / 7.5 / 2\n",
    "            \n",
    "            df5['y_head_loc'] = df5[\"y_min_t\"] + df5['ob_head_y']\n",
    "  \n",
    "\n",
    "            # Find object degree of angle, data is sorted by score, select person with highest score\n",
    "            df5['object_x_angle'] = df5['x_loc'].apply(lambda x: -(imageWidthCenter - x) * pixelDegreeHorizontal)\n",
    "            df5['object_y_angle'] = df5['y_loc'].apply(lambda x: (imageHeightCenter - x) * pixelDegreeVertical)\n",
    "            df5['head_y_angle'] = df5['y_head_loc'].apply(lambda x: (imageHeightCenter - x) * pixelDegreeVertical)\n",
    "\n",
    "            df6 = df5.loc[(df5['classes'] == 1 ) %  (df5['scores'] > person_threshold)]\n",
    "            #df6 = df6.loc[df6['scores'] > 0.80]\n",
    "\n",
    "            if (df6.empty) or (df6.iloc[0]['scores'] < person_threshold):\n",
    "                continue\n",
    "\n",
    "\n",
    "            for i in range(0,len(df6.index)):\n",
    "\n",
    "    \n",
    "\n",
    "                w = int(df6.iloc[i]['ob_wid_x'])\n",
    "                x = int(df6.iloc[i]['x_min_t'])\n",
    "                h = int(df6.iloc[i]['ob_hgt_y'])\n",
    "                y = int(df6.iloc[i][\"y_min_t\"])\n",
    "\n",
    "                HAOB = df6.iloc[i]['object_x_angle'] \n",
    "                HAOB_str = str(round(HAOB, 4))\n",
    "                \n",
    "                VAOB = df6.iloc[i]['object_y_angle']\n",
    "                VAOB_str = str(round(VAOB, 4))\n",
    "                \n",
    "                head_AOB = df6.iloc[i]['head_y_angle']\n",
    "                head_size = df6.iloc[i]['ob_head_y']\n",
    "                head_y  = df6.iloc[i]['y_head_loc']\n",
    "#                 print y,h,VAOB\n",
    "#                 print head_y, head_size,head_AOB\n",
    "   \n",
    "\n",
    "                #labelBuffer = int(df6.iloc[0]['y_min_t']) - int(df6.iloc[0]['ob_hgt_y'] * 0.1)\n",
    "\n",
    "                # print\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                #cv2.putText(image_np, AOB_str, (int(df6.iloc[0]['x_min_t']), labelBuffer), font, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "                halfBody = h / 3\n",
    "                bigBody1 = w * 3\n",
    "                bigBody2 = x - (w * 2)\n",
    "                #roi = image_np[y:y + halfBody, x:x + w]\n",
    "                #cv2.rectangle(image_np, (x,y), (x+w, y+halfBody), (0, 255, 0), 2)\n",
    "                #cv2.imwrite('save_image/' + \"frame%d.jpg\" % count, roi)\n",
    "\n",
    "\n",
    "                wid.append(w)\n",
    "                hei.append(h)\n",
    "                head_hei.append(head_size)\n",
    "                px.append(x)\n",
    "                py.append(y)\n",
    "                pxa.append(HAOB)\n",
    "                pya.append(VAOB)\n",
    "                pyha.append(head_AOB)\n",
    "                #print boxes\n",
    "\n",
    "\n",
    "\n",
    "       # print wid, hei, px, py\n",
    "        sess.close()\n",
    "        print('Took {} seconds to find people in image'.format(timeit.default_timer() - start_time))\n",
    "\n",
    "\n",
    "        #         cv2.imshow(\"Presentation Tracker\", cv2.resize(roi, (640, 480)))\n",
    "        #         plt.figure(figsize=IMAGE_SIZE)\n",
    "        #         plt.imshow(roi)\n",
    "        #         if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        #             cv2.destroyAllWindows()\n",
    "        #             break\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "##################### Perform Pistol Draw Recognition #######################\n",
    "\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "        \n",
    "        for person in range(0,5):\n",
    "\n",
    "            with tf.Session() as sess2:\n",
    "\n",
    "                # Feed the image_data as input to the graph and get first prediction\n",
    "                softmax_tensor = sess2.graph.get_tensor_by_name('final_result:0') # 'final_result:0'\n",
    "\n",
    "               \n",
    "\n",
    "                # while True:\n",
    "                #             frame = grabVideoFeed()\n",
    "\n",
    "                #             if frame is None:\n",
    "                #                 raise SystemError('Issue grabbing the frame')\n",
    "                halfBody = hei[person] / 3\n",
    "                roi = image_np[int(py[person]):int(py[person]) + int(halfBody), int(px[person]):int(px[person]) + int(wid[person])]\n",
    "\n",
    "                frame = cv2.resize(roi, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                # adhere to TS graph input structure\n",
    "                numpy_frame = np.asarray(frame)\n",
    "                numpy_frame = cv2.normalize(numpy_frame.astype('float'), None, -0.5, .5, cv2.NORM_MINMAX)\n",
    "                numpy_final = np.expand_dims(numpy_frame, axis=0)\n",
    "\n",
    "        \n",
    "                # make prediciton\n",
    "                predictions = sess2.run(softmax_tensor, {'Mul:0': numpy_final})\n",
    "    \n",
    "                score = predictions.item(1)\n",
    "                gunScore = str(score)\n",
    "\n",
    " \n",
    "                #cv2.rectangle(image_np, (px[person],py[person]), (px[person]+wid[person], py[person]+hei[person]), (0, 0, 255), 2)\n",
    "                #cv2.rectangle(image_np, (px[person],py[person]), (px[person]+wid[person], py[person]+hei[person]), (0, 255, 0), 2)\n",
    "\n",
    "                if score > person_gun_threshold:\n",
    "                    person_count += 1\n",
    "                    cv2.rectangle(image_np, (px[person],py[person]), (px[person]+wid[person], py[person]+ (int(head_hei[person]) * 2)), (0, 0, 255), 10)\n",
    "                    labelBuffer = int(py[person]) - int(hei[person] * 0.1)\n",
    "\n",
    "                    # print\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(image_np, gunScore, (int(px[person]), labelBuffer), font, 0.8, (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Package bounding box info for ES\n",
    "                    xmin = px[person] \n",
    "                    xmax = (px[person] + wid[person])\n",
    "                    ymin = py[person] \n",
    "                    ymax = (py[person] + (int(head_hei[person] * 2)))\n",
    "                    \n",
    "                    tdoc = {\n",
    "                        'timestamp': datetime.now(),\n",
    "                        'content': 'Video information',\n",
    "                        'text': 'Object detected.',\n",
    "                        'xmin': xmin,\n",
    "                        'xmax': xmax,\n",
    "                        'ymin': ymin,\n",
    "                        'ymax': ymax,\n",
    "                    }\n",
    "                    \n",
    "                    # Send results to ES\n",
    "                    res = es.index(index=\"reception-west\", doc_type=\"_doc\", body=tdoc)\n",
    "                    print('ES document sent.')\n",
    "                    print(tdoc)\n",
    "                    \n",
    "                    cv2.imwrite('save_image/' + \"frame%d.jpg\" % person_count, image_np)\n",
    "                    print(\"Horizontal Angle\" + str(pxa[person]) )\n",
    "                    print(\" Vertical Angle \" + str(pya[person]))\n",
    "                    print(\" Head Vertical Angle \" + str(pyha[person]))        \n",
    "                    \n",
    "                cv2.putText(frame, gunScore, (10, 200), font, 0.8, (0, 255, 0), 2)\n",
    "                sess2.close()\n",
    "                print('Took {} seconds to perform image recognition on people found'.format(timeit.default_timer() - start_time))\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',cv2.resize(image_np, (1024, 768)))\n",
    "    #else:\n",
    "    #    cap=cv2.VideoCapture(\"C:/FrameData/ReceptionWestVideo.mp4\")\n",
    "    #    print(\"Restarted video capture\")\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()        \n",
    "        \n",
    "#                 print y,h,VAOB\n",
    "#                 print head_y, head_size,head_AOB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
